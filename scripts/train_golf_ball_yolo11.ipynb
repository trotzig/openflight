{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Train YOLOv11n for Golf Ball Detection\n\nFine-tunes YOLOv11 nano on golf ball datasets from Roboflow Universe.\n\n**Available Datasets:**\n- `anna-gaming` - 17,460 images (recommended - best balance)\n- `golf-ball-detection` - 5,785 images (faster training)\n- `ratsstech` - 1,383 images (quick test)\n- `golf-ball-tracker` - 458 images (smallest)\n\n**Instructions:**\n1. Open in Google Colab\n2. Runtime > Change runtime type > GPU (T4 or better)\n3. Get a free Roboflow API key at https://app.roboflow.com/settings/api\n4. Run all cells\n5. Download the trained model at the end\n\nTraining time: ~30-60 min depending on dataset size and GPU"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies\n",
    "!pip install roboflow ultralytics -q\n",
    "print(\"Dependencies installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration - EDIT THESE VALUES\nROBOFLOW_API_KEY = \"\"  # Get from https://app.roboflow.com/settings/api\n\n# Dataset mode: \"single\" or \"combined\"\nMODE = \"combined\"  # Recommended: combines multiple smaller datasets\n\n# For single mode, choose one:\nDATASET = \"golf-ball-detection\"  # 5,785 images\n\n# For combined mode, these datasets will be merged:\nCOMBINE_DATASETS = [\n    \"golf-ball-detection\",  # 5,785 images\n    \"ratsstech\",            # 1,383 images  \n    \"golf-ball-tracker\",    # 458 images\n]\n# Total: ~7,600 images - trains in ~20-30 min\n\n# Training settings\nEPOCHS = 100\nIMAGE_SIZE = 640\nBATCH_SIZE = 16  # Reduce to 8 if you get OOM errors"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Download dataset(s) from Roboflow Universe\nimport os\nimport shutil\nimport yaml\nfrom roboflow import Roboflow\n\nrf = Roboflow(api_key=ROBOFLOW_API_KEY)\n\n# Dataset configurations - workspace/project from Universe URLs\nDATASETS = {\n    \"anna-gaming\": {\n        \"workspace\": \"anna-gaming\",\n        \"project\": \"golfball\",\n    },\n    \"golf-ball-detection\": {\n        \"workspace\": \"golf-ball-detection\",\n        \"project\": \"golf-ball-detection-hii2e\",\n    },\n    \"golf-ball-tracker\": {\n        \"workspace\": \"golf-balls\",\n        \"project\": \"golf-ball-tracker-sksye\",\n    },\n    \"ratsstech\": {\n        \"workspace\": \"ratsstech-tjn5n\",\n        \"project\": \"golf-ball-detector-9cehw\",\n    }\n}\n\ndef download_dataset(ds_name):\n    \"\"\"Download a dataset, auto-detecting the latest version.\"\"\"\n    config = DATASETS[ds_name]\n    project = rf.workspace(config[\"workspace\"]).project(config[\"project\"])\n    \n    # Get all versions and find the latest\n    versions = project.versions()\n    if not versions:\n        raise RuntimeError(f\"No versions found for {ds_name}\")\n    \n    # Get the last version object from the list (latest)\n    latest = versions[-1]\n    print(f\"  Found {len(versions)} version(s), using latest\")\n    \n    return latest.download(\"yolov11\")\n\nif MODE == \"single\":\n    # Download single dataset\n    print(f\"Downloading {DATASET}...\")\n    dataset = download_dataset(DATASET)\n    dataset_location = dataset.location\n    print(f\"\\nDataset: {DATASET}\")\n    print(f\"Location: {dataset_location}\")\n\nelse:\n    # Download and combine multiple datasets\n    print(\"Downloading and combining datasets...\")\n    combined_dir = os.path.abspath(\"combined_dataset\")  # Use absolute path\n    os.makedirs(f\"{combined_dir}/train/images\", exist_ok=True)\n    os.makedirs(f\"{combined_dir}/train/labels\", exist_ok=True)\n    os.makedirs(f\"{combined_dir}/valid/images\", exist_ok=True)\n    os.makedirs(f\"{combined_dir}/valid/labels\", exist_ok=True)\n    \n    total_train = 0\n    total_valid = 0\n    \n    for ds_name in COMBINE_DATASETS:\n        print(f\"\\nDownloading {ds_name}...\")\n        dataset = download_dataset(ds_name)\n        \n        # Copy train images and labels\n        src_train_img = f\"{dataset.location}/train/images\"\n        src_train_lbl = f\"{dataset.location}/train/labels\"\n        if os.path.exists(src_train_img):\n            for f in os.listdir(src_train_img):\n                shutil.copy(f\"{src_train_img}/{f}\", f\"{combined_dir}/train/images/{ds_name}_{f}\")\n                total_train += 1\n        if os.path.exists(src_train_lbl):\n            for f in os.listdir(src_train_lbl):\n                shutil.copy(f\"{src_train_lbl}/{f}\", f\"{combined_dir}/train/labels/{ds_name}_{f}\")\n        \n        # Copy valid images and labels\n        src_valid_img = f\"{dataset.location}/valid/images\"\n        src_valid_lbl = f\"{dataset.location}/valid/labels\"\n        if os.path.exists(src_valid_img):\n            for f in os.listdir(src_valid_img):\n                shutil.copy(f\"{src_valid_img}/{f}\", f\"{combined_dir}/valid/images/{ds_name}_{f}\")\n                total_valid += 1\n        if os.path.exists(src_valid_lbl):\n            for f in os.listdir(src_valid_lbl):\n                shutil.copy(f\"{src_valid_lbl}/{f}\", f\"{combined_dir}/valid/labels/{ds_name}_{f}\")\n    \n    # Create combined data.yaml with ABSOLUTE paths\n    data_yaml = {\n        \"train\": f\"{combined_dir}/train/images\",\n        \"val\": f\"{combined_dir}/valid/images\",\n        \"nc\": 1,\n        \"names\": [\"golf-ball\"]\n    }\n    with open(f\"{combined_dir}/data.yaml\", \"w\") as f:\n        yaml.dump(data_yaml, f)\n    \n    dataset_location = combined_dir\n    print(f\"\\n{'='*40}\")\n    print(f\"Combined dataset created!\")\n    print(f\"Training images: {total_train}\")\n    print(f\"Validation images: {total_valid}\")\n    print(f\"Location: {dataset_location}\")\n    print(f\"{'='*40}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check dataset structure\nimport os\n\nprint(\"Dataset contents:\")\n!ls -la \"{dataset_location}\"\nprint(\"\\ndata.yaml:\")\n!cat \"{dataset_location}/data.yaml\"\n\n# Count images\ntrain_path = f\"{dataset_location}/train/images\"\nvalid_path = f\"{dataset_location}/valid/images\"\ntrain_count = len(os.listdir(train_path)) if os.path.exists(train_path) else 0\nvalid_count = len(os.listdir(valid_path)) if os.path.exists(valid_path) else 0\nprint(f\"\\nTraining images: {train_count}\")\nprint(f\"Validation images: {valid_count}\")\nprint(f\"Total: {train_count + valid_count}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load YOLOv11 nano (optimized for edge devices)\n",
    "model = YOLO('yolo11n.pt')\n",
    "print(\"Loaded YOLOv11n base model\")\n",
    "print(f\"Parameters: {sum(p.numel() for p in model.model.parameters()):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Train the model\nresults = model.train(\n    data=f\"{dataset_location}/data.yaml\",\n    epochs=EPOCHS,\n    imgsz=IMAGE_SIZE,\n    batch=BATCH_SIZE,\n    patience=20,          # Early stopping\n    device=0,\n    workers=2,\n    project='golf_ball_detector',\n    name='yolo11n_golfball',\n    pretrained=True,\n    optimizer='AdamW',\n    lr0=0.001,\n    augment=True,\n    hsv_h=0.015,          # Hue augmentation\n    hsv_s=0.7,            # Saturation augmentation  \n    hsv_v=0.4,            # Value augmentation\n    degrees=15,           # Rotation\n    scale=0.5,            # Scale augmentation\n    fliplr=0.5,           # Horizontal flip\n    mosaic=1.0,           # Mosaic augmentation\n)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "metrics = model.val()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"FINAL METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"mAP50:     {metrics.box.map50:.3f}\")\n",
    "print(f\"mAP50-95:  {metrics.box.map:.3f}\")\n",
    "print(f\"Precision: {metrics.box.mp:.3f}\")\n",
    "print(f\"Recall:    {metrics.box.mr:.3f}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if metrics.box.map50 > 0.8:\n",
    "    print(\"\\nExcellent! Model is ready for production.\")\n",
    "elif metrics.box.map50 > 0.6:\n",
    "    print(\"\\nGood performance. Consider more training data for improvement.\")\n",
    "else:\n",
    "    print(\"\\nModel may need more training or data augmentation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to multiple formats for Raspberry Pi\n",
    "import shutil\n",
    "\n",
    "best_model = YOLO('golf_ball_detector/yolo11n_golfball/weights/best.pt')\n",
    "\n",
    "# PyTorch format (most compatible)\n",
    "shutil.copy('golf_ball_detector/yolo11n_golfball/weights/best.pt', 'golf_ball_yolo11n.pt')\n",
    "print(\"Saved PyTorch model: golf_ball_yolo11n.pt\")\n",
    "\n",
    "# ONNX format (good CPU performance)\n",
    "best_model.export(format='onnx', imgsz=IMAGE_SIZE, simplify=True)\n",
    "shutil.copy('golf_ball_detector/yolo11n_golfball/weights/best.onnx', 'golf_ball_yolo11n.onnx')\n",
    "print(\"Saved ONNX model: golf_ball_yolo11n.onnx\")\n",
    "\n",
    "# NCNN format (optimized for ARM/Pi)\n",
    "best_model.export(format='ncnn', imgsz=IMAGE_SIZE)\n",
    "!zip -r -q golf_ball_yolo11n_ncnn.zip golf_ball_detector/yolo11n_golfball/weights/best_ncnn_model/\n",
    "print(\"Saved NCNN model: golf_ball_yolo11n_ncnn.zip\")\n",
    "\n",
    "print(\"\\nAll exports complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Test on sample images\nimport glob\nfrom IPython.display import Image, display\n\n# Get a few validation images\nval_images = glob.glob(f\"{dataset_location}/valid/images/*\")[:3]\n\nprint(\"Testing on validation images:\")\nfor img_path in val_images:\n    results = best_model.predict(img_path, conf=0.3, save=True, project='test_results')\n    print(f\"Detected {len(results[0].boxes)} golf ball(s) in {img_path.split('/')[-1]}\")\n\n# Show results\nresult_images = glob.glob('test_results/predict*/*.jpg')[:3]\nfor img in result_images:\n    display(Image(filename=img, width=400))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download trained models\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading models...\")\n",
    "print(\"\\n1. PyTorch model (.pt) - use with ultralytics\")\n",
    "files.download('golf_ball_yolo11n.pt')\n",
    "\n",
    "print(\"\\n2. ONNX model (.onnx) - use with onnxruntime\")\n",
    "files.download('golf_ball_yolo11n.onnx')\n",
    "\n",
    "print(\"\\n3. NCNN model (.zip) - optimized for ARM/Raspberry Pi\")\n",
    "files.download('golf_ball_yolo11n_ncnn.zip')\n",
    "\n",
    "print(\"\\nAll downloads complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy to Raspberry Pi\n",
    "\n",
    "```bash\n",
    "# Copy model to Pi\n",
    "scp golf_ball_yolo11n.onnx pi@<ip>:~/openlaunch/models/\n",
    "\n",
    "# Or for NCNN (faster on Pi)\n",
    "scp golf_ball_yolo11n_ncnn.zip pi@<ip>:~/openlaunch/models/\n",
    "ssh pi@<ip> 'cd ~/openlaunch/models && unzip golf_ball_yolo11n_ncnn.zip'\n",
    "\n",
    "# Start OpenLaunch with the new model\n",
    "cd ~/openlaunch\n",
    "./scripts/start-kiosk.sh --camera-model models/golf_ball_yolo11n.onnx\n",
    "\n",
    "# Or with NCNN\n",
    "./scripts/start-kiosk.sh --camera-model models/golf_ball_detector/yolo11n_golfball/weights/best_ncnn_model\n",
    "```\n",
    "\n",
    "### Recommended Model Format\n",
    "- **ONNX** - Best compatibility, good performance\n",
    "- **NCNN** - Fastest on Raspberry Pi ARM CPU\n",
    "- **PyTorch (.pt)** - Most flexible, requires more memory"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}